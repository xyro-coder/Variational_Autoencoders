{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import inspect\n",
    "import scipy\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"input_size\" : 784,\n",
    "          \"hidden_layer1\" : 512,\n",
    "          \"hidden_layer2\" : 256,\n",
    "          \"bottleneck\" : 128,\n",
    "          \"hidden_layer3\" : 256,\n",
    "          \"hidden_layer4\" : 512,\n",
    "          \"learning_rate\" : 0.001,\n",
    "          \"number_epoch\" : 100,\n",
    "          \"batch_size\" : 100\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 8.48MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 340kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.03MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transformation, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transformation, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=config[\"input_size\"], hidden_layer1=config[\"hidden_layer1\"], hidden_layer2=config[\"hidden_layer2\"], bottleneck=config[\"bottleneck\"], hidden_layer3=config[\"hidden_layer3\"], hidden_layer4=config[\"hidden_layer4\"]):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoding_layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer1, hidden_layer2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer2, bottleneck)\n",
    "        )\n",
    "\n",
    "        self.decoding_layers = nn.Sequential(\n",
    "            nn.Linear(bottleneck, hidden_layer3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer3, hidden_layer4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer4, input_size)\n",
    "        )  \n",
    "    def encoder_forward(self, data_vector):\n",
    "        # make some error handling here later hopefully \n",
    "        # q_phi(z|x) is what we want to calculate here, we assume q_phi(z|x) is a from a normal\n",
    "        # we must find mew and sigma^2 for the normal \n",
    "        # to find the following we take the data vector and put in its latent representation  \n",
    "        # q_phi(z|x) is approximatly N_phi(z|x) with paramters mew and sigma as phi\n",
    "\n",
    "        encoder_output = self.encoding_layers(data_vector).detach().numpy()\n",
    "    \n",
    "\n",
    "        mew = np.sum(encoder_output, axis=0)\n",
    "        log_sigma = np.log(np.sqrt(np.var(encoder_output, axis=0)))\n",
    "\n",
    "        return mew,  log_sigma\n",
    "    def decoder_forward(self, mew, log_sigma):\n",
    "        #z = u + sigma * eita^i\n",
    "        #eita ~ N(0, 1)\n",
    "\n",
    "        eita = scipy.stats.norm.rvs(loc=0, scale=1, size=config['bottleneck'])\n",
    "        latent_space =  scipy.stats.norm.rvs(loc=mew, scale=abs(log_sigma*eita), size=config['batch_size'])\n",
    "        print(latent_space.shape)\n",
    "\n",
    "\n",
    "        for i in range(config['bottleneck']):\n",
    "            log_sigma_eita = abs(log_sigma[i] * eita[i])\n",
    "            latent_space[i] = scipy.stats.norm.rvs(loc=mew[i], scale=(log_sigma_eita))\n",
    "\n",
    "        latent_space = torch.from_numpy(latent_space).reshape(-1, config[\"bottleneck\"]).type(torch.float32)\n",
    "        \n",
    "        decoder_output = self.decoding_layers(latent_space)\n",
    "\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(data_vector, output_vector, mew, log_sigma):\n",
    "    L_2 = nn.MSELoss(data_vector, output_vector)\n",
    "    K_L = np.log(1/log_sigma) + ((log_sigma**2 + mew**2)/2) - 0.5\n",
    "    return L_2 + K_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "size does not match the broadcast shape of the parameters. 100, (100,), (128,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m mew, log_sigma \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mencoder_forward(image_vector)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(log_sigma\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 20\u001b[0m reconstructed_image \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mdecoder_forward(mew, log_sigma)\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m Cost(image_vector, reconstructed_image, mew, log_sigma)\n\u001b[1;32m     24\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[109], line 39\u001b[0m, in \u001b[0;36mVariationalAutoencoder.decoder_forward\u001b[0;34m(self, mew, log_sigma)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecoder_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, mew, log_sigma):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#z = u + sigma * eita^i\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#eita ~ N(0, 1)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     eita \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mrvs(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottleneck\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m     latent_space \u001b[38;5;241m=\u001b[39m  scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mrvs(loc\u001b[38;5;241m=\u001b[39mmew, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mabs\u001b[39m(log_sigma\u001b[38;5;241m*\u001b[39meita), size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(latent_space\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottleneck\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:1049\u001b[0m, in \u001b[0;36mrv_generic.rvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1047\u001b[0m discrete \u001b[38;5;241m=\u001b[39m kwds\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscrete\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1048\u001b[0m rndm \u001b[38;5;241m=\u001b[39m kwds\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1049\u001b[0m args, loc, scale, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_args_rvs(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m   1050\u001b[0m cond \u001b[38;5;241m=\u001b[39m logical_and(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argcheck(\u001b[38;5;241m*\u001b[39margs), (scale \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(cond):\n",
      "File \u001b[0;32m<string>:6\u001b[0m, in \u001b[0;36m_parse_args_rvs\u001b[0;34m(self, loc, scale, size)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:931\u001b[0m, in \u001b[0;36mrv_generic._argcheck_rvs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m([bcdim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m bcdim \u001b[38;5;241m==\u001b[39m szdim\n\u001b[1;32m    929\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m (bcdim, szdim) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(bcast_shape, size_)])\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[0;32m--> 931\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize does not match the broadcast shape of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    932\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe parameters. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbcast_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    934\u001b[0m param_bcast \u001b[38;5;241m=\u001b[39m all_bcast[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    935\u001b[0m loc_bcast \u001b[38;5;241m=\u001b[39m all_bcast[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: size does not match the broadcast shape of the parameters. 100, (100,), (128,)"
     ]
    }
   ],
   "source": [
    "Model = VariationalAutoencoder()\n",
    "sig = inspect.signature(VariationalAutoencoder.__init__)\n",
    "keys_list = [key for key in sig.parameters.keys() if key != 'self']\n",
    "Model = VariationalAutoencoder(*[config[key] for key in keys_list])\n",
    "optimizer = optim.Adam(Model.parameters(), lr=config[\"learning_rate\"])\n",
    "losses = []\n",
    "for epoch in range(config[\"number_epoch\"]):\n",
    "    epoch_loss = []\n",
    "    for (i, (image_matrix, label) )in enumerate(train_loader):       \n",
    "        #Forward pass\n",
    "        image_vector = image_matrix.reshape(-1, config[\"input_size\"])\n",
    "\n",
    "        image_vector = image_vector.type(torch.float32)\n",
    "\n",
    "\n",
    "        mew, log_sigma = Model.encoder_forward(image_vector)\n",
    "        print(log_sigma.shape)\n",
    "\n",
    "\n",
    "        reconstructed_image = Model.decoder_forward(mew, log_sigma)\n",
    "\n",
    "\n",
    "        loss = Cost(image_vector, reconstructed_image, mew, log_sigma)\n",
    "        losses.append(loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "        #backpropogation\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config[\"number_epoch\"]}], Avg Loss: {avg_loss:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
