{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import inspect\n",
    "import scipy\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"input_size\" : 784,\n",
    "          \"hidden_layer1\" : 512,\n",
    "          \"hidden_layer2\" : 256,\n",
    "          \"bottleneck\" : 128,\n",
    "          \"hidden_layer3\" : 256,\n",
    "          \"hidden_layer4\" : 512,\n",
    "          \"learning_rate\" : 0.001,\n",
    "          \"number_epoch\" : 100,\n",
    "          \"batch_size\" : 100\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 333kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.41MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transformation, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transformation, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=config[\"input_size\"], hidden_layer1=config[\"hidden_layer1\"], hidden_layer2=config[\"hidden_layer2\"], bottleneck=config[\"bottleneck\"], hidden_layer3=config[\"hidden_layer3\"], hidden_layer4=config[\"hidden_layer4\"]):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoding_layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer1, hidden_layer2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer2, bottleneck)\n",
    "        )\n",
    "\n",
    "        self.decoding_layers = nn.Sequential(\n",
    "            nn.Linear(bottleneck, hidden_layer3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer3, hidden_layer4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer4, input_size)\n",
    "        )  \n",
    "    def encoder_forward(self, data_vector):\n",
    "        # make some error handling here later hopefully \n",
    "        # q_phi(z|x) is what we want to calculate here, we assume q_phi(z|x) is a from a normal\n",
    "        # we must find mew and sigma^2 for the normal \n",
    "        # to find the following we take the data vector and put in its latent representation  \n",
    "        # q_phi(z|x) is approximatly N_phi(z|x) with paramters mew and sigma as phi\n",
    "\n",
    "        encoder_output = self.encoding_layers(data_vector).detach().numpy()\n",
    "        # i have a matrix here that is size 100 by 128, for every column we should get 2 features mew and sigma\n",
    "\n",
    "        mews = np.zeros((config['batchsize']), 1)\n",
    "        log_sigmas = np.zeros((config['batch_size'], config['bottleneck']))\n",
    "    \n",
    "        for i in range(config['bottleneck']):\n",
    "            mews[:, i] = np.sum(encoder_output[:, i])\n",
    "\n",
    "            log_sigmas[:, i] = np.log(np.sqrt(np.var(encoder_output[:, i])))\n",
    "\n",
    "        return mews , log_sigmas\n",
    "\n",
    "    def decoder_forward(self, mews, log_sigmas):\n",
    "        #z = u + sigma * eita^i\n",
    "        #eita ~ N(0, 1)\n",
    "        # 100 by 128\n",
    "        eita = scipy.stats.norm.rvs(loc=0, scale=1, size=config['bottleneck'])\n",
    "        latent_space = mews + log_sigmas * eita\n",
    "        latent_space =  torch.from_numpy(latent_space).reshape(-1, config[\"bottleneck\"]).type(torch.float32)\n",
    "        \n",
    "        decoder_output = self.decoding_layers(latent_space)\n",
    "\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(data_vector, output_vector, mews, log_sigmas):\n",
    "    MSE = nn.MSELoss()\n",
    "    L_2 = MSE(data_vector, output_vector)\n",
    "\n",
    "    # K_L = np.dot(np.log(1/log_sigmas), ((log_sigmas**2 + mews**2)/2)) - 0.5\n",
    "    return L_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "9.886867\n",
      "-2.8278992\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m image_vector \u001b[38;5;241m=\u001b[39m image_vector\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_vector\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 16\u001b[0m mews, log_sigmas \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mencoder_forward(image_vector)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(mews\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m:\n",
      "Cell \u001b[0;32mIn[81], line 36\u001b[0m, in \u001b[0;36mVariationalAutoencoder.encoder_forward\u001b[0;34m(self, data_vector)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(encoder_output[:, i]))\n\u001b[0;32m---> 36\u001b[0m     log_sigmas[:, i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mvar(encoder_output[:, i])))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mews , log_sigmas\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "Model = VariationalAutoencoder()\n",
    "sig = inspect.signature(VariationalAutoencoder.__init__)\n",
    "keys_list = [key for key in sig.parameters.keys() if key != 'self']\n",
    "Model = VariationalAutoencoder(*[config[key] for key in keys_list])\n",
    "optimizer = optim.Adam(Model.parameters(), lr=config[\"learning_rate\"])\n",
    "losses = []\n",
    "for epoch in range(config[\"number_epoch\"]):\n",
    "    epoch_loss = []\n",
    "    for (i, (image_matrix, label) )in enumerate(train_loader):       \n",
    "        #Forward pass\n",
    "        image_vector = image_matrix.reshape(-1, config[\"input_size\"])\n",
    "\n",
    "        image_vector = image_vector.type(torch.float32)\n",
    "        print(image_vector.shape)\n",
    "\n",
    "        mews, log_sigmas = Model.encoder_forward(image_vector)\n",
    "        print(mews.shape)\n",
    "        if i == 10:\n",
    "            test = mews\n",
    "            print(mews[:3])\n",
    "            break\n",
    "    break\n",
    "        # reconstructed_image = Model.decoder_forward(mews, log_sigmas)\n",
    "        # print(reconstructed_image.shape)\n",
    "\n",
    "\n",
    "        # loss = Cost(image_vector, reconstructed_image, mews, log_sigmas)\n",
    "        # print(loss)\n",
    "        # losses.append(loss.item())\n",
    "        # epoch_loss.append(loss.item())\n",
    "        \n",
    "        # #backpropogation\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step() \n",
    "\n",
    "        # avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        # if i % 100 == 0:\n",
    "        #     print(f'Epoch [{epoch+1}/{config[\"number_epoch\"]}], Avg Loss: {avg_loss:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
