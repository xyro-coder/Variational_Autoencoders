{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import inspect\n",
    "import scipy\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"input_size\" : 784,\n",
    "          \"hidden_layer1\" : 512,\n",
    "          \"hidden_layer2\" : 256,\n",
    "          \"bottleneck\" : 128,\n",
    "          \"hidden_layer3\" : 256,\n",
    "          \"hidden_layer4\" : 512,\n",
    "          \"learning_rate\" : 0.001,\n",
    "          \"number_epoch\" : 100,\n",
    "          \"batch_size\" : 100,\n",
    "          \"eps\": 1e-12\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 333kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.41MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transformation, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transformation, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=config[\"input_size\"], hidden_layer1=config[\"hidden_layer1\"], hidden_layer2=config[\"hidden_layer2\"], bottleneck=config[\"bottleneck\"], hidden_layer3=config[\"hidden_layer3\"], hidden_layer4=config[\"hidden_layer4\"]):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoding_layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer1, hidden_layer2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer2, bottleneck)\n",
    "        )\n",
    "\n",
    "        self.decoding_layers = nn.Sequential(\n",
    "            nn.Linear(bottleneck, hidden_layer3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer3, hidden_layer4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer4, input_size)\n",
    "        )  \n",
    "    def encoder_forward(self, data_vector):\n",
    "        # make some error handling here later hopefully \n",
    "        # q_phi(z|x) is what we want to calculate here, we assume q_phi(z|x) is a from a normal\n",
    "        # we must find mew and sigma^2 for the normal \n",
    "        # to find the following we take the data vector and put in its latent representation  \n",
    "        # q_phi(z|x) is approximatly N_phi(z|x) with paramters mew and sigma as phi\n",
    "\n",
    "        encoder_output = self.encoding_layers(data_vector).detach().numpy()\n",
    "\n",
    "\n",
    "        # i have a matrix here that is size 100 by 128, for every column we should get 2 features mew and sigma, 100 by 2 \n",
    "        \n",
    "        # each column is reduced to two features, the first is mew and the next is sigma\n",
    "        phi = np.zeros((config['batch_size'], 2))\n",
    "    \n",
    "        for column in range(config['batch_size']):\n",
    "            phi[column][0] = np.sum(encoder_output[column, :])\n",
    "\n",
    "            phi[column][1] = np.log(np.sqrt(np.var(encoder_output[column, :])) + config['eps'])\n",
    "\n",
    "        return phi\n",
    "\n",
    "    def decoder_forward(self, phi):\n",
    "        #z = u + sigma * eita^i\n",
    "        #eita ~ N(0, 1)\n",
    "        # 100 by 128\n",
    "        eita = scipy.stats.norm.rvs(loc=0, scale=1, size=config['batch_size'])\n",
    "        latent_space = np.zeros((config['batch_size'], config['bottleneck']))\n",
    "\n",
    "        for i in range(config['batch_size']):\n",
    "            latent_space[i:,] = torch.normal(loc=phi[i][0], scale=abs(phi[i][1]*eita[i]), size=(config['bottleneck']))\n",
    "\n",
    "        latent_space =  torch.from_numpy(latent_space).type(torch.float32)\n",
    "        \n",
    "        decoder_output = self.decoding_layers(latent_space)\n",
    "\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(data_vector, output_vector, phi):\n",
    "    MSE = nn.MSELoss()\n",
    "    L_2 = MSE(data_vector, output_vector)\n",
    "    running_kl_divergence = 0\n",
    "\n",
    "    for i in range((phi.shape[0])):\n",
    "        mew = phi[i][0]\n",
    "        log_sigma = abs(phi[i][1])\n",
    "\n",
    "        running_kl_divergence += -0.5 * (1 + np.log(log_sigma**2+config['eps']) - mew**2 - log_sigma**2)\n",
    "    return L_2 + running_kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "normal() received an invalid combination of arguments - got (scale=numpy.float64, size=int, loc=numpy.float64, ), but expected one of:\n * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)\n * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)\n * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)\n * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[177], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m image_vector \u001b[38;5;241m=\u001b[39m image_vector\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     16\u001b[0m phi \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mencoder_forward(image_vector)\n\u001b[0;32m---> 19\u001b[0m reconstructed_image \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mdecoder_forward(phi)\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m Cost(image_vector, reconstructed_image, phi)\n\u001b[1;32m     25\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[175], line 53\u001b[0m, in \u001b[0;36mVariationalAutoencoder.decoder_forward\u001b[0;34m(self, phi)\u001b[0m\n\u001b[1;32m     50\u001b[0m latent_space \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottleneck\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 53\u001b[0m     latent_space[i:,] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39mphi[i][\u001b[38;5;241m0\u001b[39m], scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mabs\u001b[39m(phi[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39meita[i]), size\u001b[38;5;241m=\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottleneck\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     55\u001b[0m latent_space \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mfrom_numpy(latent_space)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     57\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoding_layers(latent_space)\n",
      "\u001b[0;31mTypeError\u001b[0m: normal() received an invalid combination of arguments - got (scale=numpy.float64, size=int, loc=numpy.float64, ), but expected one of:\n * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)\n * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)\n * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)\n * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "Model = VariationalAutoencoder()\n",
    "sig = inspect.signature(VariationalAutoencoder.__init__)\n",
    "keys_list = [key for key in sig.parameters.keys() if key != 'self']\n",
    "Model = VariationalAutoencoder(*[config[key] for key in keys_list])\n",
    "optimizer = optim.Adam(Model.parameters(), lr=config[\"learning_rate\"])\n",
    "losses = []\n",
    "for epoch in range(config[\"number_epoch\"]):\n",
    "    epoch_loss = []\n",
    "    for (i, (image_matrix, label) )in enumerate(train_loader):       \n",
    "        #Forward pass\n",
    "        image_vector = image_matrix.reshape(-1, config[\"input_size\"])\n",
    "\n",
    "        image_vector = image_vector.type(torch.float32)\n",
    "\n",
    "\n",
    "        phi = Model.encoder_forward(image_vector)\n",
    "\n",
    "\n",
    "        reconstructed_image = Model.decoder_forward(phi)\n",
    "\n",
    "\n",
    "\n",
    "        loss = Cost(image_vector, reconstructed_image, phi)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        #backpropogation\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config[\"number_epoch\"]}], Avg Loss: {avg_loss:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
