{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import inspect\n",
    "import scipy\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"input_size\" : 784,\n",
    "          \"hidden_layer1\" : 512,\n",
    "          \"hidden_layer2\" : 256,\n",
    "          \"bottleneck\" : 128,\n",
    "          \"hidden_layer3\" : 256,\n",
    "          \"hidden_layer4\" : 512,\n",
    "          \"learning_rate\" : 0.001,\n",
    "          \"number_epoch\" : 100,\n",
    "          \"batch_size\" : 100\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 333kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.41MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transformation, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transformation, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=config[\"input_size\"], hidden_layer1=config[\"hidden_layer1\"], hidden_layer2=config[\"hidden_layer2\"], bottleneck=config[\"bottleneck\"], hidden_layer3=config[\"hidden_layer3\"], hidden_layer4=config[\"hidden_layer4\"]):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoding_layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer1, hidden_layer2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer2, bottleneck)\n",
    "        )\n",
    "\n",
    "        self.decoding_layers = nn.Sequential(\n",
    "            nn.Linear(bottleneck, hidden_layer3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer3, hidden_layer4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer4, input_size)\n",
    "        )  \n",
    "    def encoder_forward(self, data_vector):\n",
    "        # make some error handling here later hopefully \n",
    "        # q_phi(z|x) is what we want to calculate here, we assume q_phi(z|x) is a from a normal\n",
    "        # we must find mew and sigma^2 for the normal \n",
    "        # to find the following we take the data vector and put in its latent representation  \n",
    "        # q_phi(z|x) is approximatly N_phi(z|x) with paramters mew and sigma as phi\n",
    "\n",
    "        encoder_output = self.encoding_layers(data_vector).detach().numpy()\n",
    "        # i have a matrix here that is size \n",
    "        return encoder_output\n",
    "\n",
    "        mews = np.zeros((config['batch_size'], config['bottleneck']))\n",
    "        log_sigmas = np.zeros((config['batch_size'], config['bottleneck']))\n",
    "    \n",
    "        for i in range(config['bottleneck']):\n",
    "            mews[:, i] = np.sum(encoder_output[:, i])\n",
    "\n",
    "            log_sigmas[:, i] = np.log(np.sqrt(np.var(encoder_output[:, i])))\n",
    "\n",
    "        return mews , log_sigmas\n",
    "\n",
    "    def decoder_forward(self, mews, log_sigmas):\n",
    "        #z = u + sigma * eita^i\n",
    "        #eita ~ N(0, 1)\n",
    "        # 100 by 128\n",
    "        eita = scipy.stats.norm.rvs(loc=0, scale=1, size=config['bottleneck'])\n",
    "        latent_space = mews + log_sigmas * eita\n",
    "        latent_space =  torch.from_numpy(latent_space).reshape(-1, config[\"bottleneck\"]).type(torch.float32)\n",
    "        \n",
    "        decoder_output = self.decoding_layers(latent_space)\n",
    "\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(data_vector, output_vector, mews, log_sigmas):\n",
    "    MSE = nn.MSELoss()\n",
    "    L_2 = MSE(data_vector, output_vector)\n",
    "\n",
    "    # K_L = np.dot(np.log(1/log_sigmas), ((log_sigmas**2 + mews**2)/2)) - 0.5\n",
    "    return L_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "(100, 128)\n",
      "[[ 3.33272964e-02  9.25976560e-02  7.65528530e-02 -6.95939828e-03\n",
      "   5.70941567e-02 -2.14713160e-02  1.00062042e-01 -4.04599681e-03\n",
      "  -4.65237759e-02 -3.72259244e-02 -1.07457250e-01 -2.00402327e-02\n",
      "  -6.09246157e-02  2.47358736e-02 -2.27497146e-02 -3.66539806e-02\n",
      "  -1.11992816e-02  4.95946109e-02  8.48524943e-02  2.01804675e-02\n",
      "  -9.28012002e-03  2.87452899e-02 -4.61278223e-02 -5.94379120e-02\n",
      "   4.95748632e-02 -3.53941657e-02 -1.52048431e-02  1.83844212e-02\n",
      "  -3.70296314e-02  3.80578008e-03  4.93130162e-02 -5.63535355e-02\n",
      "  -4.84489799e-02  2.04569083e-02 -6.73978552e-02 -6.26036944e-03\n",
      "  -4.80247438e-02  9.57038160e-03 -5.66737913e-02 -2.41717435e-02\n",
      "  -2.47598793e-02  2.67464947e-02  3.61792669e-02 -2.11417265e-02\n",
      "   1.25796720e-01 -4.21834365e-02 -2.93033570e-02 -2.64683878e-03\n",
      "  -1.35027766e-02 -9.28162336e-02  8.66263360e-02  3.30374688e-02\n",
      "   5.07379475e-04 -5.82166351e-02 -6.13537841e-02  8.39253739e-02\n",
      "   7.24470466e-02  4.59396802e-02  1.55020570e-02  5.94663247e-02\n",
      "   4.77380818e-03 -5.75836562e-02 -1.45488204e-02 -4.68365140e-02\n",
      "   4.13416047e-03  1.32509517e-02  2.80152280e-02 -1.88478567e-02\n",
      "   2.78569628e-02  3.17365229e-02 -1.74182430e-02 -9.63385999e-02\n",
      "  -6.51294813e-02 -3.70334163e-02 -6.11743936e-03  4.82987389e-02\n",
      "  -1.44262053e-02 -3.89565639e-02  9.15144086e-02  4.01253253e-02\n",
      "  -2.77680587e-02  9.42963436e-02  3.78009817e-03 -4.09595072e-02\n",
      "   5.05987145e-02 -3.38855162e-02 -3.68142314e-03 -7.70747513e-02\n",
      "   3.32854874e-02 -1.23690153e-02  7.18929544e-02  7.46914046e-03\n",
      "   3.62649448e-02 -3.08370627e-02  3.75208408e-02  3.70375440e-02\n",
      "  -2.45562419e-02  5.71016297e-02 -5.77603392e-02 -7.63692409e-02\n",
      "  -6.55401200e-02  2.01521050e-02  4.46170047e-02  1.38004113e-03\n",
      "   2.11515129e-02  1.80439577e-02 -1.20167071e-02 -1.07123964e-01\n",
      "   8.33139643e-02 -2.71750856e-02  2.03904938e-02 -1.01774640e-01\n",
      "   8.20358172e-02 -6.07978739e-02 -2.34260298e-02  6.07833872e-03\n",
      "   2.22747270e-02  2.91356090e-02  5.38053513e-02 -7.93589726e-02\n",
      "   9.68631823e-03  8.36498961e-02  3.17757614e-02  3.53588834e-02\n",
      "   4.87663001e-02  3.29839066e-02 -8.38185102e-02  4.84788343e-02]\n",
      " [ 3.84450071e-02  1.36388063e-01  6.55757114e-02  2.79327836e-02\n",
      "   6.24890402e-02 -6.18992224e-02  1.08126976e-01 -3.21103982e-03\n",
      "   1.39301131e-02 -6.55188560e-02 -8.59772637e-02 -4.06147689e-02\n",
      "  -4.27922681e-02  3.32641751e-02 -6.01830566e-03  7.02140533e-05\n",
      "  -4.61881002e-03  5.13269529e-02  1.27517253e-01 -8.04401934e-03\n",
      "  -5.93565814e-02  7.79601261e-02 -1.18141659e-01 -7.19172731e-02\n",
      "   4.97444272e-02  1.01096425e-02  1.99034996e-02 -7.38972127e-02\n",
      "  -5.70891090e-02 -4.23183329e-02  6.16424382e-02 -2.06338391e-02\n",
      "   3.18283192e-03  3.59922834e-02 -7.70221129e-02  2.90888678e-02\n",
      "  -1.26179010e-01  7.59326816e-02 -1.95660759e-02 -2.19414923e-02\n",
      "  -6.25740457e-03 -3.25160958e-02 -3.31022427e-03  1.08315041e-02\n",
      "   1.07132159e-01 -4.80987243e-02  4.59978776e-03  2.94335466e-03\n",
      "   5.05242385e-02 -8.94055516e-02  1.34099573e-01  1.31418370e-02\n",
      "  -2.07954179e-02 -4.65859734e-02 -1.00717627e-01  5.15390895e-02\n",
      "   5.10494933e-02  2.66777277e-02 -3.09940195e-03  3.03662606e-02\n",
      "   1.20952604e-02 -9.08886343e-02 -1.32715926e-02 -4.77709901e-03\n",
      "  -1.42084211e-02 -9.55018681e-03  9.43836197e-02 -6.44453838e-02\n",
      "   8.50820821e-03  1.10909939e-01 -4.45321091e-02 -1.00337431e-01\n",
      "   6.35438086e-03 -3.43559962e-03  3.08289938e-02  7.89414905e-03\n",
      "  -9.19740871e-02 -2.40190532e-02  1.17467798e-01  3.08653042e-02\n",
      "  -3.81400622e-02  9.84751061e-03 -9.59402788e-03 -4.25629243e-02\n",
      "   6.49823099e-02 -9.58429426e-02  1.37717649e-02 -8.90216902e-02\n",
      "   3.43192518e-02  3.26531567e-02  1.26291201e-01  1.73016619e-02\n",
      "  -1.45329265e-02 -3.32610197e-02  1.02757953e-01  4.35049944e-02\n",
      "   8.40382185e-03  2.76828893e-02 -7.16541931e-02 -4.89090532e-02\n",
      "  -3.46009880e-02 -6.76096184e-03  5.40039912e-02 -2.31562015e-02\n",
      "  -1.18686184e-02  9.25665908e-03  1.05359033e-02 -1.07087880e-01\n",
      "   4.92219850e-02 -9.80038568e-02  1.21806115e-04 -1.26762927e-01\n",
      "   8.74762088e-02 -5.83562106e-02  5.29334368e-03  7.20245857e-03\n",
      "   1.79572571e-02  2.01305281e-02  4.60663587e-02 -1.32320806e-01\n",
      "   1.97329000e-02  4.63788919e-02  4.50725444e-02  5.20462617e-02\n",
      "   2.69025527e-02  3.65019813e-02 -1.58372745e-01  1.10393643e-01]\n",
      " [ 8.56862310e-03  1.44339100e-01  8.75853226e-02 -9.78527498e-03\n",
      "   5.79389594e-02 -6.27734065e-02  9.41443741e-02 -2.77214125e-02\n",
      "   2.75334832e-03 -6.26121387e-02 -1.09911114e-01  2.57335193e-02\n",
      "  -2.38479208e-02 -2.38579661e-02 -3.53744067e-02 -2.99755920e-04\n",
      "  -2.80075390e-02  7.34119937e-02  3.44951823e-02  1.42139262e-02\n",
      "  -2.61426680e-02  6.63344041e-02 -1.28657967e-01 -2.36846488e-02\n",
      "   4.41417135e-02  4.48488537e-03  1.20218387e-02 -1.35815293e-02\n",
      "  -1.42526859e-02 -4.43546288e-02  6.12414964e-02 -5.67322522e-02\n",
      "  -5.15673757e-02  1.15710972e-02 -6.42461628e-02  3.56018506e-02\n",
      "  -5.25525436e-02  4.96480316e-02 -2.12060511e-02 -8.49463865e-02\n",
      "   2.88764760e-02 -1.84334442e-02  4.07572351e-02  1.60115547e-02\n",
      "   7.55234435e-02 -8.22134912e-02 -4.20974195e-02 -6.31677434e-02\n",
      "  -5.28958021e-03 -1.18528597e-01  7.47788772e-02  4.25071083e-02\n",
      "   1.56435333e-02 -8.98898318e-02 -5.58891632e-02  6.65207952e-02\n",
      "   5.40533029e-02  6.22371510e-02 -7.61882169e-03  2.99352780e-02\n",
      "  -3.87557037e-02 -7.96712935e-02 -2.52041519e-02 -7.38083944e-02\n",
      "   2.38523446e-02 -6.10308908e-03  7.93119669e-02 -1.43486829e-02\n",
      "  -6.36177231e-03  1.02977328e-01 -2.11056904e-03 -1.10848613e-01\n",
      "  -1.02344468e-01  1.00696590e-02  8.14648718e-03 -7.99822342e-03\n",
      "  -8.61063451e-02 -6.09934069e-02  6.00680485e-02  6.97217658e-02\n",
      "  -2.10385490e-02  9.75710973e-02  5.59189804e-02 -2.82621384e-03\n",
      "   3.98344696e-02 -5.57651408e-02  3.13680433e-03 -1.04848728e-01\n",
      "   3.27123366e-02 -5.01709320e-02  9.51497406e-02  2.74001956e-02\n",
      "   2.32449174e-02 -4.24283072e-02  3.67000587e-02  4.99495566e-02\n",
      "  -6.23010173e-02  6.50481656e-02 -6.97493777e-02 -6.44775806e-03\n",
      "  -1.09553553e-01  1.94484890e-02  7.66962916e-02 -4.20399271e-02\n",
      "   1.80561002e-02 -1.04403542e-02 -6.38019945e-03 -1.47564322e-01\n",
      "   9.01302025e-02 -1.98564641e-02  6.44861683e-02 -9.12055299e-02\n",
      "   7.62365982e-02 -1.39126573e-02 -9.98580549e-03  3.01924013e-02\n",
      "   3.66808549e-02  3.30365300e-02  1.26292398e-02 -6.81600496e-02\n",
      "   4.20979112e-02  9.06390101e-02  5.58361120e-04  1.93084627e-02\n",
      "   8.32070131e-03  6.74685910e-02 -1.10046066e-01  4.13600467e-02]]\n"
     ]
    }
   ],
   "source": [
    "Model = VariationalAutoencoder()\n",
    "sig = inspect.signature(VariationalAutoencoder.__init__)\n",
    "keys_list = [key for key in sig.parameters.keys() if key != 'self']\n",
    "Model = VariationalAutoencoder(*[config[key] for key in keys_list])\n",
    "optimizer = optim.Adam(Model.parameters(), lr=config[\"learning_rate\"])\n",
    "losses = []\n",
    "for epoch in range(config[\"number_epoch\"]):\n",
    "    epoch_loss = []\n",
    "    for (i, (image_matrix, label) )in enumerate(train_loader):       \n",
    "        #Forward pass\n",
    "        image_vector = image_matrix.reshape(-1, config[\"input_size\"])\n",
    "\n",
    "        image_vector = image_vector.type(torch.float32)\n",
    "        print(image_vector.shape)\n",
    "\n",
    "        mews, log_sigmas = Model.encoder_forward(image_vector)\n",
    "        print(mews.shape)\n",
    "        if i == 10:\n",
    "            test = mews[:3]\n",
    "            print()\n",
    "            break\n",
    "    break\n",
    "        # reconstructed_image = Model.decoder_forward(mews, log_sigmas)\n",
    "        # print(reconstructed_image.shape)\n",
    "\n",
    "\n",
    "        # loss = Cost(image_vector, reconstructed_image, mews, log_sigmas)\n",
    "        # print(loss)\n",
    "        # losses.append(loss.item())\n",
    "        # epoch_loss.append(loss.item())\n",
    "        \n",
    "        # #backpropogation\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step() \n",
    "\n",
    "        # avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        # if i % 100 == 0:\n",
    "        #     print(f'Epoch [{epoch+1}/{config[\"number_epoch\"]}], Avg Loss: {avg_loss:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
